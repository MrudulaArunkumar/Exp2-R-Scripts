---
title: "Exp2_data"
author: "Mrudula"
date: "28/10/2020"
output: html_document
---

This is the Data Analysis collected from Prolific for the second version of the Experiment that brought back the distractor words towards the center and the number appears either at the top or bottom.

The design looks like this. 


![Design of the experiment.](D:/PhD/Experiments/Exp2 Overshadowing/ExpDocumentation/Exp2Design.jpg)

Loading the libraries and the relevant data files

```{r library and files, include=FALSE, message=FALSE}
sessionInfo()#saving the R session

library(tidyverse)
library(plyr)
library(ez)
library(schoRsch)
library(knitr)
library(pander)
library(rmarkdown)
library(lme4)
library(reshape2)

#clearing environment
rm(list = ls())

#setting up working directory globally only needed when using it first time
# library(here)
# set_here()

#loading data from the files
Exp2data <- read.csv("D:/PhD/Experiments/Exp2 Overshadowing/Data/Exp2 Prolific/Exp2_fulldataset.csv")


attach(Exp2data)



```

2.  Checking balance in design and all trials and conditions are balanced.

```{r design Check, include = FALSE}
#blockcount
table(Block)
table(Block,Condition) #29 refers to the NA rows
table(Block,Condition, Validity)

#position
table(PositionD)
table(PositionT)
table(Saliency)

detach(Exp2data)
```

Cleaning data : removing unnecessaary columns, filling Screen background and block count to every cell, splitting the RT column and changed the units to ms and creating a column for Error Rate

```{r cleaning, include=FALSE}

Exp2data <- Exp2data %>%
  select(-X,-consentkey.keys,-consentkey.rt,-beginexp.rt,-beginexp.keys,-checkresp.corr,-checkresp.rt,-checkresp.keys,
         -Attention.ran,-Attention.thisIndex,-Attention.thisN,-Attention.thisTrialN,-Attention.thisRepN,
         -Question,-Solution,-gotoPrac.rt,-gotoPrac.keys,-InstRep.ran,-InstRep.thisIndex,-InstRep.thisN,-InstRep.thisTrialN,-InstRep.thisRepN,
         -Prac_start.rt,-Prac_start.keys,-prctrials.ran,-prctrials.thisIndex,-prctrials.thisN,-prctrials.thisRepN,-prctrials.thisRepN,
         -pracend.keys,-pracend.rt,-PracRepeat.ran,-PracRepeat.thisIndex,-PracRepeat.thisN,-PracRepeat.thisRepN,-PracRepeat.thisTrialN)

#removing unwanted columns in the experimental side 
Exp2data <- Exp2data %>%
  select(-firstlearntrials.ran,-firstlearntrials.thisIndex,-firstlearntrials.thisRepN,-firstlearntrials.thisTrialN,
         -brkcontinue.keys,-Exptrials.ran,-Exptrials.thisIndex,-Exptrials.thisTrialN, - Exptrials.thisRepN,
         -afterpause.keys,-blocks.ran,-blocks.thisIndex,-blocks.thisTrialN,-blocks.thisRepN,
         -CAproceed.rt,-CAproceed.keys,-ContAwareness.ran,-ContAwareness.thisIndex,-ContAwareness.thisN,-ContAwareness.thisTrialN,-ContAwareness.thisRepN,
         -Questionnaire.ran,-Questionnaire.thisIndex,-Questionnaire.thisTrialN,-Questionnaire.thisRepN,-todebrief.keys,-ExpExit.keys)

#assigning the vaues of blockcount and screenbackground for every row
Exp2data <- Exp2data%>%group_by(participant)%>%fill(Screen_bg,.direction = "down")

Exp2data <- Exp2data %>% group_by(participant)%>%fill(blocks.thisN,.direction = "up")



Exp2data <- rename(Exp2data, c("blocks.thisN" = "BlockCount"))

#creating a separate df with the contingency awareness
Exp2_CA <- Exp2data %>%
  filter(Condition == "ContChkTest" | str_detect(AwareQ, "mit"))

Exp2_CA <- Exp2_CA %>% group_by(participant)%>%fill(WordPair,.direction = "down")
#adjusting RT
Exp2data <- separate(Exp2data, col = ResponseKey.rt, into = c("RT_Trials", "RT_secondary"), sep = ',')
Exp2data$RT_Trials <- Exp2data$RT_Trials%>%
  str_replace_all("\\[|\\]","")%>%
  as.double(Exp2data$RT_Trials)
Exp2data$RT_Trials <- 1000*(Exp2data$RT_Trials)
Exp2data$PreTargetDisplayTime <- 1000*(Exp2data$PreTargetDisplayTime)

Exp2data <- Exp2data%>%drop_na(RT_Trials)

Exp2data$ACC_trials <- Exp2data$ResponseKey.corr
Exp2data$ErrorRate <- 1 - Exp2data$ACC_trials

```

### Demographics

Participants' Age and Gender

```{r demo, echo=FALSE}
pander(summary(Exp2data$Age), style = 'rmarkdown', caption = "Mean Age of participants")

kable((table(Exp2data$Gender))/480, format = "html", caption = " Gender distribution")
```

Summary of the overall RT

```{r descriptive, echo=FALSE}
pander(summary(Exp2data$RT_Trials), style = 'rmarkdown',caption = 'Mean RT')
pander(table(Exp2data$ACC_trials),style = 'rmarkdown',caption = "Accuracy")

pander(round(table(Exp2data$ACC_trials)/nrow(Exp2data)*100, digits = 3), style = 'rmarkdown', caption = "Percentage of errors")

```

### Exclusion of Outliers and Farouts

Removing outliers and farouts and showing the summary of RTs for each exclusion criteria

```{r outliersfarouts, echo=FALSE}

Exp2data$RT_Trials[Exp2data$ACC_trials==0] <- NA


#creating function to remove the outliers and farouts
computeTukeys <- function(x){
  P25 <- quantile(x$RT_Trials, .25, na.rm = TRUE, type = 6) #type = 6 -> used in SPSS
  P75 <- quantile(x$RT_Trials, .75, na.rm = TRUE, type = 6)
  x$Outlier <- P75 + 1.5*(P75 - P25)
  x$Farouts <- P75 + 3.0*(P75 - P25)
  return(x)
}


#identifying the outliers and farouts at individual level
Exp2data <- ddply(Exp2data, .(participant), computeTukeys)

#creating new column with RT trials after removing outliers/farouts
Exp2data$RT_ifo <- Exp2data$RT_Trials
Exp2data$RT_io <- Exp2data$RT_Trials
Exp2data$RT_ifo[Exp2data$RT_ifo > Exp2data$Farouts|Exp2data$RT_ifo < 300] <- NA
Exp2data$RT_io[Exp2data$RT_io > Exp2data$Outlier|Exp2data$RT_io < 300] <- NA

pander(summary(Exp2data$RT_ifo), style = 'rmarkdown', caption = "Summary of RT after removing Farouts")
pander(summary(Exp2data$RT_io), style = 'rmarkdown', caption = "Summary of RT after removing Outliers")


```

## Analysis of Validity across all trials

There is a strong validity effect in all the trials where valid trials are faster than learn trials


```{r alltrials, echo = FALSE, warning=FALSE}
Exp2agg <- aggregate(data = Exp2data,RT_ifo~participant+Validity+Condition,mean)


anova_agg <- ezANOVA(data = Exp2agg,
        dv = RT_ifo,
        wid = participant,
        within = .(Validity,Condition),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_agg, style = "rmarkdown", caption = "ANOVa table for all trials with validity and condition as factors",split.table = Inf, missing = NA)

ezPlot(data = Exp2agg,
        dv = RT_ifo,
        wid = participant,
        within = .(Validity,Condition),
       x=Condition,split = Validity, do_bars = FALSE)+
  ylim(550,600)+theme_classic()+
  ggtitle("Mean RT per condition for valid and invalid trials")
```

Splitting the data as learn and test trials to analyze individually

```{r}
Exp2learn <- Exp2data %>%
  filter(Condition == "learn")

Exp2test <- Exp2data %>%
  filter(Condition == "test")

Exp2learn<- Exp2learn%>%
  mutate(PositionMatch = ifelse(as.character(PositionD)==as.character(PositionT),"same","different"))

```

## Analysis for learn trials

#### 1. Farouts

A strong validity effect between valid learn trials and invalid learn trials

```{r learnfo, echo = FALSE, message=FALSE}
Exp2learn <- Exp2learn %>%
  select(Validity,Saliency,Condition,PositionD,PositionT,Distractor1,Distractor2,Screen_bg,everything())

#aggregate
Exp2agg_l_fo <- aggregate(data = Exp2learn,RT_ifo~participant+Validity,mean)
#kable(Exp2agg_l_fo, format = "html", caption = "Summary of RTs of valid and invalid trials")

#convert to wide
Exp2agg_l_fo_wide <- spread(Exp2agg_l_fo, Validity,RT_ifo)
Exp2agg_l_fo_wide$ValEffect <- Exp2agg_l_fo_wide$invalid - Exp2agg_l_fo_wide$valid

pander(t.test(RT_ifo~Validity, data = Exp2agg_l_fo, paired = TRUE), style = 'rmarkdown')



```

Plot showing the validity effect per participant in learn trials

```{r echo = FALSE}
Exp2agg_l_fo_wide$participant <- as.factor(Exp2agg_l_fo_wide$participant)
ggplot(data = Exp2agg_l_fo_wide, aes(x = participant, y = ValEffect))+
  geom_bar(stat = "identity", fill = "darkslateblue")+
  theme_classic()+
  ggtitle("Validity Effect (invalid - valid) across learn trials in each participant")
```

#### 2. Outliers

Validity effect is p = 0.09, with a mean difference of 5.8s

    ```{r learno, echo = FALSE}

    #aggregate
Exp2agg_l_o <- aggregate(data = Exp2learn,RT_io~participant+Validity,mean)
Exp2agg_l_o_wide <- spread(Exp2agg_l_o, Validity,RT_io)
Exp2agg_l_o_wide$ValEffect <- Exp2agg_l_o_wide$invalid - Exp2agg_l_o_wide$valid
Exp2agg_l_o_wide$participant <- as.factor(Exp2agg_l_o_wide$participant)


pander(t.test(RT_io~Validity, data = Exp2agg_l_o, paired = TRUE), style = 'rmarkdown')


ggplot(data = Exp2agg_l_o_wide, aes(x = participant, y = ValEffect))+
  geom_bar(stat = "identity", fill = "darkslateblue")+
  theme_classic()+
  ggtitle("Validity Effect (invalid - valid) across learn trials(outliers excluded) in each participant")

    ```

#### 3. Error Rate

No significant difference in ER

```{r errorl, echo = FALSE, warning = FALSE}

Exp2agg_l_ER <- aggregate(data = Exp2learn,ErrorRate~participant+Validity,mean)

pander(t.test(ErrorRate~Validity, data =Exp2agg_l_ER, paired = TRUE), style = 'rmarkdown', caption = "t test results for error Rates", split.table = "Inf", missing = NA)

```

## Analysis of Test Trials

#### 1. Farouts

Almost significant validity effect = p.10. But no main effect of Saliency or interaction between saliency and validity.

```{r testfo, echo = FALSE, warning = FALSE}
Exp2test <- Exp2test %>%
  select(Validity,Saliency,Condition,PositionD,PositionT,Distractor1,Distractor2,Screen_bg,everything())

#aggregate
Exp2agg_t_fo <- aggregate(data = Exp2test,RT_ifo~participant+Validity+Saliency,mean)

#anova
anova_t_fo <- ezANOVA(data = Exp2agg_t_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)

pander(anova_t_fo, style = 'rmarkdown', caption = "ANOVA results: Farouts excluded for test trials",split.table = "Inf", missing = NA)


ezPlot(data = Exp2agg_t_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Saliency,Validity),
        split = Validity, x=Saliency, do_bars = FALSE)+
        theme_classic()+
        ylim(550,600)+
        ggtitle("Mean RT for valid and invalid trials across saliency")
```


```{r include =  FALSE}
#converting to wide format 
Exp2valeffect_tfo <- dcast(Exp2agg_t_fo, participant ~ Validity+Saliency, value.var = "RT_ifo")
Exp2valeffect_tfo$ValNSalEffect <- Exp2valeffect_tfo$invalid_nonsalient - Exp2valeffect_tfo$valid_nonsalient
Exp2valeffect_tfo$ValSalEffect <- Exp2valeffect_tfo$invalid_salient - Exp2valeffect_tfo$valid_salient

# boxplot(Exp2valeffect_tfo$ValSalEffect)
# boxplot(Exp2valeffect_tfo$ValNSalEffect)

```

#### 2. Outliers

Validity effect, p = 0.19 but main effect of saliency and interaction between saliency and validity are far from being significant

```{r testo, echo = FALSE, warning = FALSE}
Exp2agg_t_o <- aggregate(data = Exp2test,RT_io~participant+Validity+Saliency,mean)



anova_t_o <- ezANOVA(data = Exp2agg_t_o,
            dv = RT_io,
            wid = participant,
            within = .(Saliency,Validity),
            detailed = TRUE)
pander(anova_t_o, style = 'rmarkdown', caption = "ANOVA results: Outliers excluded for test trials", split.table = "Inf", missing = NA)
 
ezPlot(data = Exp2agg_t_o,
        dv = RT_io,
        wid = participant,
        within = .(Saliency,Validity),
        split = Validity, x=Saliency, do_bars = FALSE)+
  ylim(550,600)+theme_classic()+ggtitle("MEanRT(outleirs excluded) for valid and invalid trials across saliency")

```



```{r echo = FALSE, fig.height=10, fig.width=15}

#Effect across each participant
Exp2valeffect_to <- spread(Exp2agg_t_o, Validity, RT_io)
Exp2valeffect_to$ValEffect <- Exp2valeffect_to$invalid - Exp2valeffect_to$valid
Exp2valeffect_to$participant <- as.factor(Exp2valeffect_to$participant)

ggplot(data = Exp2valeffect_to, aes(x = Saliency, y = ValEffect, fill = Saliency))+
  geom_bar(stat = "identity")+
  theme_classic()+
  facet_grid(.~participant)+
  theme(axis.text.x = element_text(angle = 90), axis.text.x.bottom = element_blank())+
  ylab("Validity Effect")+
  ggtitle("Validity Effect (invalid - valid) across test trials(outliers excluded) in each participant")
```

### 3. Error Rate

No significant effect of ER

```{r ert, echo = FALSE, warning = FALSE}

Exp2agg_t_ER <- aggregate(data = Exp2test,ErrorRate~participant+Validity+Saliency,mean)


anova_t_ER <- ezANOVA(data = Exp2agg_t_ER,
        dv = ErrorRate,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_ER, style = 'rmarkdown', caption = "ANOVA results: ErrorRates in test trials", split.table = "Inf", missing = NA)



```

# Exploratory Analysis


## 1. Effect of screen background

How the test trials look for each backgroun
```{r}
ggplot(Exp2test, aes(x = Saliency, y = RT_ifo, color = Validity))+
  stat_summary(fun = mean, geom = "point")+
  facet_grid(.~Screen_bg)+theme_classic()+ggtitle("RT across validity and Saliency for the different background colour")
```

Spliting the data based on background
```{r bg, echo=FALSE}
whitebg <-  Exp2test %>%
  subset(Screen_bg == "white")

whitebg <- aggregate(data = whitebg, RT_ifo~participant+Validity+Saliency,mean)

anova_wBG <- ezANOVA(data = whitebg,
                     dv = RT_ifo,
                     wid = participant,
                     within =  .(Saliency,Validity),
                     detailed = TRUE)

pander(anova_wBG, style = "rmarkdown", caption = "ANOVA for white background")

##for black bg
blackbg <-  Exp2test %>%
  subset(Screen_bg == "black")

blackbg <- aggregate(data = blackbg, RT_ifo~participant+Validity+Saliency,mean)

anova_bBG <- ezANOVA(data = blackbg,
                     dv = RT_ifo,
                     wid = participant,
                     within =  .(Saliency,Validity),
                     detailed = TRUE)

pander(anova_bBG, style = "rmarkdown", caption = "ANOVA for black background")




```

## 2. Adding the factor of Position

This analysis discusses the effect of salient word and the position of the number. Position Match variable indicates whether the salient word position and number appeared in the same place or not. Although this may not be of help because we brought the words closer together, I added this factor anyway to see how the data is.


## Analysis of learn trials - Position

#### 1. Farouts

Significant main validity effect when position Match is factored in. 
```{r learnp, echo=FALSE, warning=FALSE}


#aggregate
Exp2agg_lp_fo <- aggregate(data = Exp2learn,RT_ifo~participant+Validity+PositionMatch+Screen_bg,mean)


lp_anova <- ezANOVA(data = Exp2agg_lp_fo,
        dv=RT_ifo,
        wid = participant,
        within = .(Validity, PositionMatch),
        detailed = TRUE)

panderOptions('table.split.table',300)
pander(lp_anova, style = 'rmarkdown',caption = "ANOVA with RTs , Validity and Position Match", split.table = "Inf", missing = NA)

ezPlot(data = Exp2agg_lp_fo,
        dv=RT_ifo,
        wid = participant,
        within = .(PositionMatch,Validity),
        split = Validity,x=PositionMatch, do_bars = FALSE)+
      theme_classic()+
        ylim(550,600)+ggtitle("RTs when position match between salient word and number in learn trials (farouts excluded)")

```

### 2. Outliers

Almost significant validity effect(p = .09) when PositionMatch of salient word and number is factored in the ANOVA

```{r learnpo, echo = FALSE, warning = FALSE, message = FALSE}
Exp2agg_lp_o <- aggregate(data = Exp2learn,RT_io~participant+Validity+PositionMatch,mean)

lp_anova_o <- ezANOVA(data = Exp2agg_lp_o,
        dv=RT_io,
        wid = participant,
        within = .(Validity, PositionMatch),
        detailed = TRUE)

panderOptions('table.split.table',300)
pander(lp_anova_o,style = 'rmarkdown', caption = "ANOVA with RT(w/o OUtliers) and validity and position Match", split.table = "Inf", missing = NA)

ezPlot(data = Exp2agg_lp_o,
      dv=RT_io,
      wid = participant,
      within = .(Validity, PositionMatch),
      split = Validity, x=PositionMatch, do_bars = FALSE)+
      ylim(550,600)+
      theme_classic()+ggtitle("RTs when position match between salient word and number in learn trials (outliers excluded)")

```

### 3. Error Rate



```{r errorlp, echo = FALSE, warning = FALSE}

Exp2agg_lp_ER <- aggregate(data =Exp2learn,ErrorRate~participant+Validity+PositionMatch,mean)

lp_anova_er <- ezANOVA(data = Exp2agg_lp_ER,
        dv=ErrorRate,
        wid = participant,
        within = .(Validity, PositionMatch),
        detailed = TRUE)

pander(lp_anova_er,style = 'rmarkdown', caption = "ANOVA of error rate in learn trials with validity and position match", split.table = "Inf", missing = NA)

```

## Analysis of test trials - Position

### 1. Farouts

Main effect of Validity when Position of Number is factored in is almost significant , p = .10 

```{r testpfo, echo=FALSE, warning = FALSE}

#aggregate
Exp2agg_tp_fo <- aggregate(data = Exp2test,RT_ifo~participant+Validity+Saliency+PositionT,mean)


tp_anova <- ezANOVA(data = Exp2agg_tp_fo,
        dv=RT_ifo,
        wid = participant,
        within = .(Validity, PositionT,Saliency),
        detailed = TRUE)
pander(tp_anova,style = 'rmarkdown', captions = "ANOVA with RTs(w/o farouts) with Position of Target and Validity", split.table = "Inf", missing = NA)

ezPlot(data = Exp2agg_tp_fo,
        dv=RT_ifo,
        wid = participant,
        within = .(Validity, PositionT,Saliency),
       split = Validity, x=Saliency, do_bars = FALSE)+
  ylim(550,600)+theme_classic()+
  facet_grid(~PositionT)+
  ggtitle("Mean RT of valid and invalid trials across saliency for both positions of target")

```

### 2. Outliers

Main effect of Validity and Position both have F values greater than 1, unlike the farouts

```{r testpo, echo = FALSE, warning = FALSE, message = FALSE}
Exp2agg_tp_o <- aggregate(data = Exp2test,RT_io~participant+Validity+Saliency+PositionT,mean)


tp_anova_o <- ezANOVA(data = Exp2agg_tp_o,
    dv=RT_io,
    wid = participant,
    within = .(Validity, PositionT, Saliency),
    detailed = TRUE)

panderOptions('table.split.table',300)
pander(tp_anova_o,style = 'rmarkdown', caption = "ANOVA of RT(w/o Outliers) and validity and POsition of Target")

ezPlot(data = Exp2agg_tp_o,
    dv=RT_io,
    wid = participant,
    within = .(Validity, PositionT,Saliency),
    split = Validity, x=Saliency, do_bars = FALSE)+ylim(550,600)+theme_classic()+
  facet_grid(~PositionT)+ggtitle("Mean RT of valid and invalid trials across saliency for both positions of target")

```

### 3. Error Rate

No significant difference in Error Rate

```{r errorp, include=FALSE, warning=FALSE, message=FALSE}

Exp2agg_tp_ER <- aggregate(data = Exp2test,ErrorRate~participant+Validity+PositionT+Saliency,mean)

tp_anova_er <- ezANOVA(data = Exp2agg_tp_ER,
        dv=ErrorRate,
        wid = participant,
        within = .(Validity, PositionT,Saliency),
        detailed = TRUE)
pander(tp_anova_er,style = 'rmarkdown', caption = "ANOVA with error rate and position of Target", split.table = "Inf", missing = NA)

# ezPlot(data = Exp2agg_tp_ER,
#         dv=ErrorRate,
#         wid = participant,
#         within = .(Validity, PositionT,Saliency),
#        split = Validity, x = Saliency, do_bars = FALSE)+
#   facet_grid(~PositionT)+theme_classic()+ylim(0,0.15)+ggtitle("Mean Error Rate for test trials")
```

## Contingency Awareness Analysis

```{r CAadd , include = FALSE}
#Words
#create a new dataframethat has the values from EXp2_CA awareness Qs as each column and then check for wordpair and if the word pair and key for each question match then we can say whether it is accurate/salient or not.

Exp2_CA <- Exp2_CA %>%
  mutate(WordPrediction = ifelse(WordPair == 1 & Questionnaire.thisN == 2 & AwarenessResp.keys == "l", 1, ifelse(WordPair == 1 & Questionnaire.thisN == 3 & AwarenessResp.keys == "a",1, ifelse(WordPair == 1 & Questionnaire.thisN == 4 & AwarenessResp.keys == "l",1,ifelse(WordPair==1 & Questionnaire.thisN == 5 & AwarenessResp.keys == "a",1,NA)))))

Exp2_CA <- Exp2_CA %>%
  mutate(WordPrediction = ifelse(WordPair == 2 & Questionnaire.thisN == 2 & AwarenessResp.keys == "a" & is.na(WordPrediction) == TRUE, 1, ifelse(WordPair == 2 & Questionnaire.thisN == 3 & AwarenessResp.keys == "a" & is.na(WordPrediction) == TRUE,1, ifelse(WordPair == 2 & Questionnaire.thisN == 4 & AwarenessResp.keys == "l" & is.na(WordPrediction) == TRUE,1,ifelse(WordPair==2 & Questionnaire.thisN == 5 & AwarenessResp.keys == "l" & is.na(WordPrediction) == TRUE,1,NA)))))

Exp2_CA <- Exp2_CA %>%
  mutate(WordPrediction = ifelse(WordPair == 3 & Questionnaire.thisN == 2 & AwarenessResp.keys == "a"& is.na(WordPrediction) == TRUE, 1, ifelse(WordPair == 3 & Questionnaire.thisN == 3 & AwarenessResp.keys == "l"& is.na(WordPrediction) == TRUE,1, ifelse(WordPair == 3 & Questionnaire.thisN == 4 & AwarenessResp.keys == "a" & is.na(WordPrediction) == TRUE,1,ifelse(WordPair==3 & Questionnaire.thisN == 5 & AwarenessResp.keys == "l" & is.na(WordPrediction) == TRUE,1,NA)))))

Exp2_CA <- Exp2_CA %>%
  mutate(WordPrediction = ifelse(WordPair == 4 & Questionnaire.thisN == 2 & AwarenessResp.keys == "l"& is.na(WordPrediction) == TRUE, 1, ifelse(WordPair == 4 & Questionnaire.thisN == 3 & AwarenessResp.keys == "l"& is.na(WordPrediction) == TRUE,1, ifelse(WordPair == 4 & Questionnaire.thisN == 4 & AwarenessResp.keys == "a" & is.na(WordPrediction) == TRUE,1,ifelse(WordPair==4 & Questionnaire.thisN == 5 & AwarenessResp.keys == "a" & is.na(WordPrediction) == TRUE,1,NA)))))

#Adding all the relevant variables to a separate dataframe
CA_Summary <- Exp2_CA %>%
  dplyr::group_by(participant) %>%
  dplyr::summarise(TotalAcc = sum(CA_RespKey.corr, na.rm=TRUE),
                   MeanAcc = mean(CA_RespKey.corr, na.rm=TRUE),
                   EvenYes = sum(AwarenessResp.keys == "j" & Questionnaire.thisN ==0,na.rm = TRUE),
                   OddYes = sum(AwarenessResp.keys == "j" & Questionnaire.thisN ==1,na.rm = TRUE),
                   OddNo = sum(AwarenessResp.keys == "n" & Questionnaire.thisN ==1,na.rm = TRUE),
                   EvenNo = sum(AwarenessResp.keys == "n" & Questionnaire.thisN ==0,na.rm = TRUE),
                   AccWordPrediction = sum(WordPrediction, na.rm = TRUE))

CA_Summary$participant <- as.factor(CA_Summary$participant)
table(CA_Summary$participant,CA_Summary$TotalAcc)
```

```{r CAplots , include = FALSE}
ggplot(CA_Summary, aes(x=participant, y = TotalAcc))+
  geom_bar(stat = "identity", fill = "darkslateblue")+
  theme_classic()+ggtitle("Accuracy of Awareness trials per participants")

ppGuessaboveag <- c(14,16,25,26,31,32,33,34,38,43,42,47,49,51,53)
```


### ANOVA after filtering out participants who did better in CA trials

```{r}
Exp2CAAboveAvg <- Exp2agg_t_fo %>%
  filter(participant%in%ppGuessaboveag)

anova_CA <- ezANOVA(data = Exp2CAAboveAvg,
                    dv = RT_ifo,
                    wid = participant,
                    within = .(Saliency, Validity),
                    detailed = TRUE)

pander(anova_CA, style = "rmarkdown", caption = "ANOVA of RTs of participants who scored above average")

ezPlot(data = Exp2CAAboveAvg,
                    dv = RT_ifo,
                    wid = participant,
                    within = .(Saliency, Validity),
                    split = Validity, x = Saliency, do_bars = FALSE)+
  ylim(500,600)+theme_classic()+ggtitle("Interaction between validity and saliency for participants who scored above average in CA trials")

library(Hmisc)
Exp2CAbelowAvg <- Exp2agg_t_fo %>%
  filter(participant%nin%ppGuessaboveag)

is.na(Exp2CAbelowAvg)

anova_nonCA <- ezANOVA(data = Exp2CAbelowAvg,
                    dv = RT_ifo,
                    wid = participant,
                    within = .(Saliency, Validity),
                    detailed = TRUE)
pander(anova_nonCA)


ezPlot(data = Exp2CAbelowAvg,
                    dv = RT_ifo,
                    wid = participant,
                    within = .(Saliency, Validity),
                    split = Validity, x = Saliency, do_bars = FALSE)+
  ylim(550,610)+
  theme_classic()+ggtitle("Interaction between validity and saliency for participants who scored below average in CA trials")

```

