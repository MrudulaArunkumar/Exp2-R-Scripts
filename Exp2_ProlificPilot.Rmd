---
title: "Exp2_pilotdata_prolific"
author: "Mrudula"
date: "20/10/2020"
output: html_document
---

This is the Pilot Data Analysis collected from Prolific for the second version of the Experiment that brought back the distractor words towards the center and the number appears either at the top or bottom.

Loading the libraries and the relevant data files

```{r library and files, include=FALSE, message=FALSE}
sessionInfo()#saving the R session

library(tidyverse)
library(plyr)
library(ez)
library(schoRsch)
library(knitr)
library(pander)
library(rmarkdown)

#clearing environment
rm(list = ls())

#setting up working directory globally only needed when using it first time
library(here)
set_here()

#loading pilot
d1 <- read.csv("D:/PhD/Experiments/Exp2 Overshadowing/Data/Pilot/Prolific Pilot/1pp.csv")
d2 <- read.csv("D:/PhD/Experiments/Exp2 Overshadowing/Data/Pilot/Prolific Pilot/8pp.csv")
d3 <- read.csv("D:/PhD/Experiments/Exp2 Overshadowing/Data/Pilot/Prolific Pilot/4pp.csv")
d4 <- read.csv("D:/PhD/Experiments/Exp2 Overshadowing/Data/Pilot/Prolific Pilot/6pp.csv")
d5 <- read.csv("D:/PhD/Experiments/Exp2 Overshadowing/Data/Pilot/Prolific Pilot/7pp.csv")

table(d4$ResponseKey.corr)

d1$preResp.rt <- 0
d2$preResp.rt <- 0

#d4 has too many errors
Exp2_ProlificPilot <- rbind(d1,d2,d3,d5)

table(Exp2_ProlificPilot$preResp.rt)
sum(is.na(Exp2_ProlificPilot$preResp.rt))

#write.csv(Exp2_ProlificPilot, file = "ProlificPilot.csv")
attach(Exp2_ProlificPilot)



```

2. Checking balance in design and all trials and conditions are balanced.

```{r design Check, include = FALSE}
#blockcount
table(Block)
table(Block,Condition) #29 refers to the NA rows
table(Block,Condition, Validity)

#position
table(PositionD)
table(PositionT)
table(Saliency)

detach(Exp2_ProlificPilot)
```

Cleaning data : removing unnecessaary columns, filling Screen background and block count to every cell, splitting the RT column and changed the units to ms and creating a column for Error Rate

```{r cleaning, include=FALSE}

Exp2_ProlificPilot <- Exp2_ProlificPilot %>%
  select(-consentkey.keys,-consentkey.rt,-beginexp.rt,-beginexp.keys,-checkresp.corr,-checkresp.rt,-checkresp.keys,
         -Attention.ran,-Attention.thisIndex,-Attention.thisN,-Attention.thisTrialN,-Attention.thisRepN,
         -Question,-Solution,-gotoPrac.rt,-gotoPrac.keys,-InstRep.ran,-InstRep.thisIndex,-InstRep.thisN,-InstRep.thisTrialN,-InstRep.thisRepN,
         -Prac_start.rt,-Prac_start.keys,-prctrials.ran,-prctrials.thisIndex,-prctrials.thisN,-prctrials.thisRepN,-prctrials.thisRepN,
         -pracend.keys,-pracend.rt,-PracRepeat.ran,-PracRepeat.thisIndex,-PracRepeat.thisN,-PracRepeat.thisRepN,-PracRepeat.thisTrialN)

#removing unwanted columns in the experimental side 
Exp2_ProlificPilot <- Exp2_ProlificPilot %>%
  select(-firstlearntrials.ran,-firstlearntrials.thisIndex,-firstlearntrials.thisRepN,-firstlearntrials.thisTrialN,
         -brkcontinue.keys,-Exptrials.ran,-Exptrials.thisIndex,-Exptrials.thisTrialN, - Exptrials.thisRepN,
         -afterpause.keys,-blocks.ran,-blocks.thisIndex,-blocks.thisTrialN,-blocks.thisRepN,
         -CAproceed.rt,-CAproceed.keys,-ContAwareness.ran,-ContAwareness.thisIndex,-ContAwareness.thisN,-ContAwareness.thisTrialN,-ContAwareness.thisRepN,
         -Questionnaire.ran,-Questionnaire.thisIndex,-Questionnaire.thisTrialN,-Questionnaire.thisRepN,-todebrief.keys,-ExpExit.keys)

#assigning the vaues of blockcount and screenbackground for every row
Exp2_ProlificPilot <- Exp2_ProlificPilot%>%group_by(participant)%>%fill(Screen_bg,.direction = "down")

Exp2_ProlificPilot <- Exp2_ProlificPilot %>% group_by(participant)%>%fill(blocks.thisN,.direction = "up")

Exp2_ProlificPilot <- rename(Exp2_ProlificPilot, c("blocks.thisN" = "BlockCount"))

Exp2_CA <- Exp2_ProlificPilot %>%
  filter(Condition == "ContChkTest" | str_detect(AwareQ, "mit"))

#adjusting RT
Exp2_ProlificPilot <- separate(Exp2_ProlificPilot, col = ResponseKey.rt, into = c("RT_Trials", "RT_secondary"), sep = ',')
Exp2_ProlificPilot$RT_Trials <- Exp2_ProlificPilot$RT_Trials%>%
  str_replace_all("\\[|\\]","")%>%
  as.double(Exp2_ProlificPilot$RT_Trials)
Exp2_ProlificPilot$RT_Trials <- 1000*(Exp2_ProlificPilot$RT_Trials)
Exp2_ProlificPilot$PreTargetDisplayTime <- 1000*(Exp2_ProlificPilot$PreTargetDisplayTime)

Exp2_ProlificPilot <- Exp2_ProlificPilot%>%drop_na(RT_Trials)

Exp2_ProlificPilot$ACC_trials <- Exp2_ProlificPilot$ResponseKey.corr
Exp2_ProlificPilot$ErrorRate <- 1 - Exp2_ProlificPilot$ACC_trials

```

Summary of the overall RT

```{r descriptive, echo=FALSE}
pander(summary(Exp2_ProlificPilot$RT_Trials), style = 'rmarkdown',caption = 'Mean RT')
pander(table(Exp2_ProlificPilot$ACC_trials),style = 'rmarkdown',caption = "Accuracy")

```

Removing outliers and farouts and showing the summary of RTs for each exclusion criteria

```{r outliersfarouts, echo=FALSE}

Exp2_ProlificPilot$RT_Trials[Exp2_ProlificPilot$ACC_trials==0] <- NA


#creating function to remove the outliers and farouts
computeTukeys <- function(x){
  P25 <- quantile(x$RT_Trials, .25, na.rm = TRUE, type = 6) #type = 6 -> used in SPSS
  P75 <- quantile(x$RT_Trials, .75, na.rm = TRUE, type = 6)
  x$Outlier <- P75 + 1.5*(P75 - P25)
  x$Farouts <- P75 + 3.0*(P75 - P25)
  return(x)
}


#identifying the outliers and farouts at individual level
Exp2_ProlificPilot <- ddply(Exp2_ProlificPilot, .(participant), computeTukeys)

#creating new column with RT trials after removing outliers/farouts
Exp2_ProlificPilot$RT_ifo <- Exp2_ProlificPilot$RT_Trials
Exp2_ProlificPilot$RT_io <- Exp2_ProlificPilot$RT_Trials
Exp2_ProlificPilot$RT_ifo[Exp2_ProlificPilot$RT_ifo > Exp2_ProlificPilot$Farouts|Exp2_ProlificPilot$RT_ifo < 300] <- NA
Exp2_ProlificPilot$RT_io[Exp2_ProlificPilot$RT_io > Exp2_ProlificPilot$Outlier|Exp2_ProlificPilot$RT_io < 300] <- NA

pander(summary(Exp2_ProlificPilot$RT_ifo), style = 'rmarkdown', caption = "Summary of RT after removing Farouts")
pander(summary(Exp2_ProlificPilot$RT_io), style = 'rmarkdown', caption = "Summary of RT after removing Outliers")


```

## Analysis of Validity across all trials

    There are no main effects or an interaction (unlike hiwi pilots) As per the plot it also looks like for test trials, valid trials are faster but for learn valid trials, they are slower. (like the hiwis)
      
```{r alltrials, echo = FALSE, warning=FALSE}
Exp2agg <- aggregate(data = Exp2_ProlificPilot,RT_ifo~participant+Validity+Condition,mean)


anova_agg <- ezANOVA(data = Exp2agg,
        dv = RT_ifo,
        wid = participant,
        within = .(Validity,Condition),
        detailed = TRUE)

pander(anova_agg, style = "markdown", caption = "ANOVa table for all trials with validity and condition as factors")

ezPlot(data = Exp2agg,
        dv = RT_ifo,
        wid = participant,
        within = .(Validity,Condition),
       x=Condition,split = Validity, do_bars = FALSE)+
  ylim(550,600)+theme_classic()
```


Splitting the data as learn and test trials to analyze individually

```{r}
Exp2learn_ProlificPilot <- Exp2_ProlificPilot %>%
  filter(Condition == "learn")

Exp2test_ProlificPilot <- Exp2_ProlificPilot %>%
  filter(Condition == "test")

Exp2learn_ProlificPilot<- Exp2learn_ProlificPilot%>%
  mutate(PositionMatch = ifelse(as.character(PositionD)==as.character(PositionT),"same","different"))

```

## Analysis for learn trials

-   Farouts

    No significant difference between valid and invalid learn trials

```{r learnfo, echo = FALSE}
Exp2learn_ProlificPilot <- Exp2learn_ProlificPilot %>%
  select(Validity,Saliency,Condition,PositionD,PositionT,Distractor1,Distractor2,everything())

#aggregate
Exp2agg_l_pp_fo <- aggregate(data = Exp2learn_ProlificPilot,RT_ifo~participant+Validity,mean)
kable(Exp2agg_l_pp_fo, format = "html", caption = "Summary of RTs of valid and invalid trials")

t.test(RT_ifo~Validity, data = Exp2agg_l_pp_fo, paired = TRUE)

```

-   Outliers

    Also no significant difference between valid and invalid learn trials

    ```{r learno, echo = FALSE}

    #aggregate
    Exp2agg_l_pp_o <- aggregate(data = Exp2learn_ProlificPilot,RT_io~participant+Validity,mean)

    t.test(RT_io~Validity, data = Exp2agg_l_pp_o, paired = TRUE)

    ```

-   Error Rate

    Why is there a difference of significance in error rate (ANOVA vs t test). In the ANOVA it shows as if there is a significant validity effect, but not from the t test.

```{r errorl, echo = FALSE, warning = FALSE}

Exp2agg_l_pp_ER <- aggregate(data = Exp2learn_ProlificPilot,ErrorRate~participant+Validity+Saliency,mean)

anova_t_ER <- ezANOVA(data = Exp2agg_l_pp_ER,
        dv = ErrorRate,
        wid = participant,
        within = .(Validity),
        detailed = TRUE)

pander(anova_t_ER, style = "markdown", caption = "ANOVA table for ERROR RATE in learn trials")
t.test(ErrorRate~Validity, data = Exp2agg_l_pp_ER, paired = TRUE)

```

## Analysis of Test Trials

-   Farouts

    There is no main effect of validity: You can see from the summary tables that it is not that different and some are infact slower in the valid condition and faster for invalid. But there seems to be an almost significant interaction between saliency and validity of test trials, in the expected direction

```{r testfo, echo = FALSE, warning = FALSE}
Exp2test_ProlificPilot <- Exp2test_ProlificPilot %>%
  select(Validity,Saliency,Condition,PositionD,PositionT,Distractor1,Distractor2,everything())

#aggregate
Exp2agg_t_pp_fo <- aggregate(data = Exp2test_ProlificPilot,RT_ifo~participant+Validity+Saliency,mean)

aggmean_t_fo <- ddply(Exp2agg_t_pp_fo, .(participant,Validity), summarize, RTmean=mean(RT_ifo), SD = sd(RT_ifo))
salmean_t_fo <- ddply(Exp2agg_t_pp_fo, .(participant,Saliency), summarize, RTmean=mean(RT_ifo), SD = sd(RT_ifo))

kable(aggmean_t_fo, format = "html", caption = "Summary means of valid vs invalid across participant")
kable(salmean_t_fo, format = "html", caption = "Summary means of Salient vs non salient across participant")

anova_t_fo <- ezANOVA(data = Exp2agg_t_pp_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)

pander(anova_t_fo, style = 'rmarkdown', caption = "ANOVA results: Farouts excluded for test trials")

ezPlot(data = Exp2agg_t_pp_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Saliency,Validity),
        split = Validity, x=Saliency, do_bars = FALSE)+
        theme_classic()+
        ylim(550,600)+
        ggtitle("Mean RT for valid and invalid trials across saliency")
```

-   Outliers

    This pattern is very different from the pattern from the farouts. There is no interaction anymore and the lines are simply alike, in the opposite direction even. Again we don't see a validity effect nor an interaction effect
   

```{r testo, echo = FALSE, warning = FALSE}
Exp2agg_t_pp_o <- aggregate(data = Exp2test_ProlificPilot,RT_io~participant+Validity+Saliency,mean)
means_t_o <- aggregate(data=Exp2agg_t_pp_o,RT_io~participant+Validity,mean)
salmeans_t_o <- aggregate(data=Exp2agg_t_pp_o,RT_io~participant+Saliency,mean)


kable(means_t_o, format = "html", caption = "Summary means of valid vs invalid across participant")
kable(salmeans_t_o, format = "html", caption = "Summary means of Salient vs non salient across participant")


anova_t_o <- ezANOVA(data = Exp2agg_t_pp_o,
            dv = RT_io,
            wid = participant,
            within = .(Saliency,Validity),
            detailed = TRUE)
pander(anova_t_o, style = 'rmarkdown', caption = "ANOVA results: Outliers excluded for test trials")
 
ezPlot(data = Exp2agg_t_pp_o,
        dv = RT_io,
        wid = participant,
        within = .(Saliency,Validity),
        split = Validity, x=Saliency, do_bars = FALSE)+
  ylim(550,600)+theme_classic()

```

-   Error Rate

    No effects in the error Rates

```{r ert, echo = FALSE, warning = FALSE}

Exp2agg_t_pp_ER <- aggregate(data = Exp2test_ProlificPilot,ErrorRate~participant+Validity+Saliency,mean)

Exp2agg_t_pp_ER$ErrorRate <- 100 * Exp2agg_t_pp_ER$ErrorRate

anova_t_ER <- ezANOVA(data = Exp2agg_t_pp_ER,
        dv = ErrorRate,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)

pander(anova_t_ER, style = 'rmarkdown', caption = "ANOVA results: ErrorRates in test trials")


```
### Exploratory: Adding the factor of Position
    
    This analysis discusses the effect of salient word and the position of the number. Position Match variable indicates whether the salient word position and number appeared in the same place or not. Although this may not be of help because we brought the words closer together, I added this factor anyway to see how the data is.

#### Analysis of learn trials - Position
-   Farouts

      NO effect and the RTs seem to be favouring the reversed condition where they are slower when the position of salient word and number match. 

```{r learnp, echo=FALSE, warning=FALSE}


#aggregate
Exp2agg_lp_pp_fo <- aggregate(data = Exp2learn_ProlificPilot,RT_ifo~participant+Validity+PositionMatch,mean)


lp_anova <- ezANOVA(data = Exp2agg_lp_pp_fo,
        dv=RT_ifo,
        wid = participant,
        within = .(Validity, PositionMatch),
        detailed = TRUE)
pander(lp_anova,style = 'rmarkdown',caption = "ANOVA with RTs , Validity and Position Match ")

ezPlot(data = Exp2agg_lp_pp_fo,
        dv=RT_ifo,
        wid = participant,
        within = .(Validity, PositionMatch),
       split = Validity, x=PositionMatch, do_bars = FALSE)+
      theme_classic()+
        ylim(550,600)

```

-   Outliers
    
    No Effects

    ```{r learnpo, echo = FALSE, warning = FALSE}
Exp2agg_lp_pp_o <- aggregate(data = Exp2learn_ProlificPilot,RT_io~participant+Validity+PositionMatch,mean)


lp_anova_o <- ezANOVA(data = Exp2agg_lp_pp_o,
        dv=RT_io,
        wid = participant,
        within = .(Validity, PositionMatch),
        detailed = TRUE)
pander(lp_anova_o,style = 'rmarkdown', caption = "ANOVA with RT(w/o OUtliers) and validity and position Match")

ezPlot(data = Exp2agg_lp_pp_o,
        dv=RT_io,
        wid = participant,
        within = .(Validity, PositionMatch),
       split = Validity, x=PositionMatch, do_bars = FALSE)+
        ylim(550,600)+
        theme_classic()

    ```

-   Error Rate

    There is a validity effect.

```{r errorlp, echo = FALSE, warning = FALSE}

Exp2agg_lp_pp_ER <- aggregate(data =Exp2learn_ProlificPilot,ErrorRate~participant+Validity+PositionMatch,mean)

lp_anova_er <- ezANOVA(data = Exp2agg_lp_pp_ER,
        dv=ErrorRate,
        wid = participant,
        within = .(Validity, PositionMatch),
        detailed = TRUE)

pander(lp_anova_er,style = 'rmarkdown', caption = "ANOVA of error rate in learn trials with validity and position match")
```

#### Analysis of test trials - Position
-   Farouts

    No effect/influence of position of number. 
```{r testpfo, echo=FALSE, warning = FALSE}

#aggregate
Exp2agg_tp_pp_fo <- aggregate(data = Exp2test_ProlificPilot,RT_ifo~participant+Validity+Saliency+PositionT,mean)


tp_anova <- ezANOVA(data = Exp2agg_tp_pp_fo,
        dv=RT_ifo,
        wid = participant,
        within = .(Validity, PositionT),
        detailed = TRUE)
pander(tp_anova,style = 'rmarkdown', captions = "ANOVA with RTs(w/o farouts) with Position of Target and Validity")

ezPlot(data = Exp2agg_tp_pp_fo,
        dv=RT_ifo,
        wid = participant,
        within = .(Validity, PositionT),
       split = Validity, x=PositionT, do_bars = FALSE)+
  ylim(550,600)+theme_classic()

```

-   Outliers

      Same as farouts, no effects and plot also looks similar 
      
    ```{r testpo, echo = FALSE, warning = FALSE}
Exp2agg_tp_pp_o <- aggregate(data = Exp2test_ProlificPilot,RT_io~participant+Validity+Saliency+PositionT,mean)


tp_anova_o <- ezANOVA(data = Exp2agg_tp_pp_o,
        dv=RT_io,
        wid = participant,
        within = .(Validity, PositionT),
        detailed = TRUE)
pander(tp_anova_o,style = 'rmarkdown', caption = "ANOVA of RT(w/o Outliers) and validity and POsition of Target")

ezPlot(data = Exp2agg_tp_pp_o,
        dv=RT_io,
        wid = participant,
        within = .(Validity, PositionT),
       split = Validity, x=PositionT, do_bars = FALSE)+ylim(550,600)+theme_classic()

    ```

-   Error Rate

    No effect

```{r errorp, echo=FALSE, warning=FALSE, message=FALSE}

Exp2agg_tp_pp_ER <- aggregate(data = Exp2test_ProlificPilot,ErrorRate~participant+Validity+PositionT,mean)

tp_anova_er <- ezANOVA(data = Exp2agg_tp_pp_ER,
        dv=ErrorRate,
        wid = participant,
        within = .(Validity, PositionT),
        detailed = TRUE)
pander(tp_anova_er,style = 'rmarkdown', caption = "ANOVA with error rate and position of Target")
```
