---
title: "Exp2_pilotdata_onlyTarget"
author: "Mrudula"
date: "13/10/2020"
output: html_document
---

This is the Pilot Data Analysis collected from the hiwis for the version of the Experiment that contains distractor words also in the target Display

Loading the libraries and the relevant data files

```{r library and files, include=FALSE, message=FALSE}
sessionInfo()#saving the R session

library(tidyverse)
library(plyr)
library(ez)
library(schoRsch)
library(knitr)
library(pander)
library(rmarkdown)

#clearing environment
rm(list = ls())

#setting up working directory globally only needed when using it first time
#library(here)
#set_here()

#loading pilot
d1 <- read.csv("D:/PhD/Experiments/Exp2 Overshadowing/Data/Pilot/1_ot.csv")
d2 <- read.csv("D:/PhD/Experiments/Exp2 Overshadowing/Data/Pilot/2_ot.csv")
d3 <- read.csv("D:/PhD/Experiments/Exp2 Overshadowing/Data/Pilot/3_ot.csv")
d4 <- read.csv("D:/PhD/Experiments/Exp2 Overshadowing/Data/Pilot/4_ot.csv")

Exp2_onlyT <- rbind(d1,d2,d3,d4)

#write.csv(Exp2_onlyT, file="Pilot_onlyT.csv")
attach(Exp2_onlyT)



```

Checking the balance in design:

*29 refers to rows containing NA*

```{r design Check}
#blockcount
table(Block)
table(Block,Condition) #29 refers to the NA rows
table(Block,Condition, Validity)

#position
table(PositionD)
table(PositionT)
table(Saliency)

detach(Exp2_onlyT)
```

Cleaning data

```{r cleaning, include=FALSE}

Exp2_onlyT <- Exp2_onlyT %>%
  select(-consentkey.keys,-consentkey.rt,-beginexp.rt,-beginexp.keys,-checkresp.corr,-checkresp.rt,-checkresp.keys,
         -Attention.ran,-Attention.thisIndex,-Attention.thisN,-Attention.thisTrialN,-Attention.thisRepN,
         -Question,-Solution,-gotoPrac.rt,-gotoPrac.keys,-InstRep.ran,-InstRep.thisIndex,-InstRep.thisN,-InstRep.thisTrialN,-InstRep.thisRepN,
         -Prac_start.rt,-Prac_start.keys,-prctrials.ran,-prctrials.thisIndex,-prctrials.thisN,-prctrials.thisRepN,-prctrials.thisRepN,
         -pracend.keys,-pracend.rt,-PracRepeat.ran,-PracRepeat.thisIndex,-PracRepeat.thisN,-PracRepeat.thisRepN,-PracRepeat.thisTrialN)

#removing unwanted columns in the experimental side 
Exp2_onlyT <- Exp2_onlyT %>%
  select(-firstlearntrials.ran,-firstlearntrials.thisIndex,-firstlearntrials.thisRepN,-firstlearntrials.thisTrialN,
         -brkcontinue.keys,-Exptrials.ran,-Exptrials.thisIndex,-Exptrials.thisTrialN, - Exptrials.thisRepN,
         -afterpause.keys,-blocks.ran,-blocks.thisIndex,-blocks.thisTrialN,-blocks.thisRepN,
         -CAproceed.rt,-CAproceed.keys,-ContAwareness.ran,-ContAwareness.thisIndex,-ContAwareness.thisN,-ContAwareness.thisTrialN,-ContAwareness.thisRepN,
         -Questionnaire.ran,-Questionnaire.thisIndex,-Questionnaire.thisTrialN,-Questionnaire.thisRepN,-todebrief.keys,-ExpExit.keys)

#assigning the vaues of blockcount and screenbackground for every row
Exp2_onlyT <- Exp2_onlyT%>%group_by(participant)%>%fill(Screen_bg,.direction = "down")

Exp2_onlyT <- Exp2_onlyT %>% group_by(participant)%>%fill(blocks.thisN,.direction = "up")

Exp2_onlyT <- rename(Exp2_onlyT, c("BlockCount" = "blocks.thisN"))

Exp2_CA <- Exp2_onlyT %>%
  filter(Condition == "ContChkTest" | str_detect(AwareQ, "mit"))

#adjusting RT
Exp2_onlyT <- separate(Exp2_onlyT, col = ResponseKey.rt, into = c("RT_Trials", "RT_secondary"), sep = ',')
Exp2_onlyT$RT_Trials <- Exp2_onlyT$RT_Trials%>%
  str_replace_all("\\[|\\]","")%>%
  as.double(Exp2_onlyT$RT_Trials)
Exp2_onlyT$RT_Trials <- 1000*(Exp2_onlyT$RT_Trials)
Exp2_onlyT$PreTargetDisplayTime <- 1000*(Exp2_onlyT$PreTargetDisplayTime)

Exp2_onlyT <- Exp2_onlyT%>%drop_na(RT_Trials)

Exp2_onlyT$ACC_trials <- Exp2_onlyT$ResponseKey.corr
Exp2_onlyT$ErrorRate <- 1 - Exp2_onlyT$ACC_trials

```

Summary of the overall RT

```{r descriptive, echo=FALSE}
pander(summary(Exp2_onlyT$RT_Trials), style = 'rmarkdown',caption = 'Mean RT')
pander(table(Exp2_onlyT$ACC_trials),style = 'rmarkdown',caption = "Accuracy")

```

Removing outliers

```{r outliersfarouts, echo=FALSE}

Exp2_onlyT$RT_Trials[Exp2_onlyT$ACC_trials==0] <- NA


#creating function to remove the outliers and farouts
computeTukeys <- function(x){
  P25 <- quantile(x$RT_Trials, .25, na.rm = TRUE, type = 6) #type = 6 -> used in SPSS
  P75 <- quantile(x$RT_Trials, .75, na.rm = TRUE, type = 6)
  x$Outlier <- P75 + 1.5*(P75 - P25)
  x$Farouts <- P75 + 3.0*(P75 - P25)
  return(x)
}


#identifying the outliers and farouts at individual level
Exp2_onlyT <- ddply(Exp2_onlyT, .(participant), computeTukeys)

#creating new column with RT trials after removing outliers/farouts
Exp2_onlyT$RT_ifo <- Exp2_onlyT$RT_Trials
Exp2_onlyT$RT_io <- Exp2_onlyT$RT_Trials
Exp2_onlyT$RT_ifo[Exp2_onlyT$RT_ifo > Exp2_onlyT$Farouts|Exp2_onlyT$RT_ifo < 300] <- NA
Exp2_onlyT$RT_io[Exp2_onlyT$RT_io > Exp2_onlyT$Outlier|Exp2_onlyT$RT_io < 300] <- NA

pander(summary(Exp2_onlyT$RT_ifo), style = 'rmarkdown', caption = "Summary of RT after removing Farouts")
pander(summary(Exp2_onlyT$RT_io), style = 'rmarkdown', caption = "Summary of RT after removing Outliers")


```

Split the data as learn and test trials

```{r}
Exp2learn_onlyT <- Exp2_onlyT %>%
  filter(Condition == "learn")

Exp2test_onlyT <- Exp2_onlyT %>%
  filter(Condition == "test")

#matching saliency and position
Exp2learn_onlyT<- Exp2learn_onlyT%>%
  mutate(PositionMatch = ifelse(as.character(PositionD)==as.character(PositionT),"same","different"))
```

## Analysis for learn trials

-   Farouts

```{r learn}
Exp2learn_onlyT <- Exp2learn_onlyT %>%
  select(Validity,Saliency,Condition,PositionD,PositionT,Distractor1,Distractor2,PositionMatch,everything())

#aggregate
Exp2agg_l_ot_fo <- aggregate(data = Exp2learn_onlyT,RT_ifo~participant+Validity+Saliency,mean)

valmeanL_fo <- ddply(Exp2agg_l_ot_fo, .(participant,Validity), summarize, RTmean=mean(RT_ifo), SD = sd(RT_ifo))
kable(valmeanL_fo, format = "html", caption = "Validity means for learn trials, farouts excluded")


t.test(RT_ifo~Validity, data = Exp2agg_l_ot_fo)

```

-   Outliers

    ```{r learno}

    #aggregate
    Exp2agg_l_ot_o <- aggregate(data = Exp2learn_onlyT,RT_io~participant+Validity+Saliency,mean)

    valmeanL_o <- ddply(Exp2agg_l_ot_o, .(participant,Validity), summarize, RTmean=mean(RT_io), SD = sd(RT_io))
    kable(valmeanL_o, format = "html", caption = "Validity means for learn trials, outliers excluded")

t.test(RT_io~Validity, data = Exp2agg_l_ot_o)


    ```

-   Error Rate

```{r error}

Exp2agg_l_ot_ER <- aggregate(data = Exp2learn_onlyT,ErrorRate~participant+Validity+PositionMatch,mean)

Exp2agg_l_ot_ER$ErrorRate <- 100 * Exp2agg_l_ot_ER$ErrorRate

ezANOVA(data = Exp2agg_l_ot_ER,
        dv=ErrorRate,
        wid = participant,
        within = .(Validity,PositionMatch),
        detailed = TRUE)


```

## Analysis of Test Trials

-   Farouts


```{r testfo}
Exp2test_onlyT <- Exp2test_onlyT%>%
  select(Validity,Saliency,Condition,PositionT,Distractor1,Distractor2,everything())

#aggregate
Exp2agg_t_ot_fo <- aggregate(data = Exp2test_onlyT,RT_ifo~participant+Validity+Saliency,mean)

aggmean_t_fo <- ddply(Exp2agg_t_ot_fo, .(participant,Validity), summarize, RTmean=mean(RT_ifo), SD = sd(RT_ifo))
salmean_t_fo <- ddply(Exp2agg_t_ot_fo, .(participant,Saliency), summarize, RTmean=mean(RT_ifo), SD = sd(RT_ifo))

kable(aggmean_t_fo, format = "html", caption = "Summary means of valid vs invalid across participant")
kable(salmean_t_fo, format = "html", caption = "Summary means of Salient vs non salient across participant")

anova_t_fo <- ezANOVA(data = Exp2agg_t_ot_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)

pander(anova_t_fo, style = 'rmarkdown', caption = "ANOVA results: Farouts excluded for test trials")

ezPlot(data = Exp2agg_t_ot_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Saliency,Validity),
        split = Validity, x=Saliency, col=PositionT, do_bars = FALSE)
```

-   Outliers



```{r}
Exp2agg_t_ot_o <- aggregate(data = Exp2test_onlyT,RT_io~participant+Validity+Saliency,mean)
means_t_o <- aggregate(data=Exp2agg_t_ot_o,RT_io~participant+Validity+PositionT,mean)
salmeans_t_o <- aggregate(data=Exp2agg_t_ot_o,RT_io~participant+Saliency+PositionT,mean)


kable(means_t_o, format = "html", caption = "Summary means of valid vs invalid across participant")
kable(salmeans_t_o, format = "html", caption = "Summary means of Salient vs non salient across participant")


anova_t_o <- ezANOVA(data = Exp2agg_t_ot_o,
            dv = RT_io,
            wid = participant,
            within = .(Saliency,Validity),
            detailed = TRUE)
pander(anova_t_o, style = 'rmarkdown', caption = "ANOVA results: Outliers excluded for test trials")
 
ezPlot(data = Exp2agg_t_ot_o,
        dv = RT_io,
        wid = participant,
        within = .(Saliency,Validity),
        split = Validity, x=Saliency, col = PositionT,do_bars = FALSE)

```

-   Error Rate

```{r}

Exp2agg_t_ot_ER <- aggregate(data = Exp2test_onlyT,ErrorRate~participant+Validity+Saliency,mean)

Exp2agg_t_ot_ER$ErrorRate <- 100 * Exp2agg_t_ot_ER$ErrorRate

anova_t_ER <- ezANOVA(data = Exp2agg_t_ot_ER,
        dv = ErrorRate,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)

pander(anova_t_ER, style = 'rmarkdown', caption = "ANOVA results: ErrorRates in test trials")


```
## Exploratory: With the factor of Position

## Analysis for learn trials with position

-   Farouts

```{r learnpfo}


#aggregate
Exp2agg_lp_ot_fo <- aggregate(data = Exp2learn_onlyT,RT_ifo~participant+Validity+PositionMatch,mean)


lpAnova <- ezANOVA(data = Exp2agg_lp_ot_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Validity,PositionMatch),
        detailed = TRUE)
pander(lpAnova, style = 'rmarkdown', caption="ANOVA with validity and the factor telling whether the position of the number and salient word is same or not")

kable(Exp2agg_lp_ot_fo, format = "html", caption = "Means of valid and invalid learn trials across participant")

ezPlot(data = Exp2agg_lp_ot_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Validity,PositionMatch),
       split = Validity,x=PositionMatch, do_bars = FALSE)
```
-  OUtliers

```{r}

#aggregate
Exp2agg_lp_ot_o <- aggregate(data = Exp2learn_onlyT,RT_io~participant+Validity+PositionMatch,mean)


lpAnova_o <- ezANOVA(data = Exp2agg_lp_ot_o,
        dv = RT_io,
        wid = participant,
        within = .(Validity,PositionMatch),
        detailed = TRUE)
pander(lpAnova_o, style = 'rmarkdown', caption="ANOVA with validity and the factor telling whether the position of the number and salient word is same or not")

kable(Exp2agg_lp_ot_o, format = "html", caption = "Means of valid and invalid learn trials across participant")

ezPlot(data = Exp2agg_lp_ot_o,
        dv = RT_io,
        wid = participant,
        within = .(Validity,PositionMatch),
       split = Validity,x=PositionMatch, do_bars = FALSE)
```

## Analysis for test with position

FArouts

```{r}
Exp2agg_tp_ot_fo <- aggregate(data = Exp2test_onlyT,RT_ifo~participant+Validity+Saliency+PositionT,mean)

anova_tp_fo <- ezANOVA(data = Exp2agg_t_ot_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Saliency,Validity,PositionT),
        detailed = TRUE)

pander(anova_tp_fo, style = 'rmarkdown', caption = "ANOVA results: Farouts excluded for test trials")

ezPlot(data = Exp2agg_tp_ot_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Saliency,Validity,PositionT),
        split = Validity, x=Saliency, col=PositionT, do_bars = FALSE)
```

-  Outliers

```{r}
Exp2agg_tp_ot_o <- aggregate(data = Exp2test_onlyT,RT_io~participant+Validity+Saliency+PositionT,mean)

anova_tp_fo <- ezANOVA(data = Exp2agg_t_ot_o,
        dv = RT_io,
        wid = participant,
        within = .(Saliency,Validity,PositionT),
        detailed = TRUE)

pander(anova_tp_o, style = 'rmarkdown', caption = "ANOVA results: Farouts excluded for test trials")

ezPlot(data = Exp2agg_tp_ot_o,
        dv = RT_io,
        wid = participant,
        within = .(Saliency,Validity,PositionT),
        split = Validity, x=Saliency, col=PositionT, do_bars = FALSE)
```

